<!DOCTYPE html>

<html lang="pt-br">
    <head>
        <meta charset="utf-8">
        <title>Introdução - Big Data</title>
        <meta name="description" content="Este é um site referênte à estudos sobre Analytics">
    </head>
    
    <body>
        <h1>Introdução - Big Data</h1>
        <p>De uma forma clara, pode-se dizer que oje, os dados são <strong>maior fonte de recursos e considerado o produto mais valioso</strong> na sociedade, uma vez que através da coleta e interpretetação desses dados, possíveis estratégias podem ser trabalhadas para agregar o produtor desses dados coletados. Ou seja, ao adquirir informações (dados) sobre algo/alguém, é possível saber o que fazer em várias situações hipotéticas com esse produtor. De certa forma, imagine que ao obter dados e informações sobre uma pessoa, uma empresa consegue criar estratégias de markwting e produtos melhores que façam interesse a seus clientes, analisando informações cmo gosto, desejos, necessidades e etc. Dessa forma, pode-se afirmar que <strong>dado/informação/conhecimento é poder!</strong></p>
        <p>Logo, o termo conhecido como <i>Big Data</i> está diretamente relacionado a esse trabalho para com os dados, porém, não basta que sejam apenas dados simples ou de "fácil" coleta, pois esses podem ser trabalhados por outros operadores, como Bancos de dados e seus administradores (os DBA's). Já para o <i>Big Data</i>, como seu nome já informa, é o trabalho direto com <strong>grandes massas de dados</strong>, tendo o objetivo de coletar e trabalhar dados em grande escala e massivos, que muitas vezes podem ser mal interpretados por quem não trabalha com estudos aprimorados. Além desses dados serem coletados, de maneira veloz, devem também ser trabalhados e distribuídos novamente em uma mesma velocidade, pois quanto mais rápido esse processo, primeiramente o analista conseguirá atingir o seu produtor dos dados.</p>
        <p>Essa análise e coleta dos dados é trabalhada por dois tipos de pessoas, os chamados <strong>engenheiros e cientistas de dados</strong>, os quais trabalham diretamente com esses dados, afim de criar estratégias, relatórios/dashboards e previsões.</p>
        <ul>
            <li><strong>Engenheiro de dados</strong></li>
                <p>Desenvolve, contrói, testa e faz a manutenção da arquitetura e no ambiente (bancos de dados e sistemas de processamento). Esses, asseguram que a arquitetura/ambiente irá supotar os requisitos do negócio. Além disso, empregam uma variedade de linguagens e ferramentam na construção das soluções, como: ferramentas ETL, Bancos de dados, construção de API e computação distribuída.</p>
                <p>Ou seja, estão diretamente ligados a parte de <strong>coleta/abtstração dos dados</strong>, visando o profissional seguinte que irá analisa-los.</p>
            <li><strong>Cientistas de dados</strong></li>
                <p>Limpam, exploram e organizam os dados para encontrar padrões escondidos nos dados. Ou seja, esses possuem a função de analisar um grande volume de dados na criação de <i>insights</i>. Além disso, empregam programas analíticos sofisticados, <i>machine learning</i> e métodos estatísticos para responder questões de negócio, como: <i>Machine Learning</i>, <i>Storytelling</i>, criação de <i>insights</i> e modelagem preditiva.</p>
                <p>Ou seja, estão diretamente ligados a funçã de <strong>analisar/trabalhar os dados</strong> que foram coletados, construindo estartégias, gráficos e previsões a partir desses dados coletados.</p>
        </ul>
        <img src="https://danielatllas.github.io/Analytics-BI/EngenheirosCientistas.png">
        <br>
        <p>Diante disso, entenda que o conceito de <i>Big Data</i> é trabalhado nas empresas chamadas de <strong>data-driven interprises</strong> (Empresar Orientadas a Dados), que são ambientes que trabalham com a essência de <strong>análises preditivas</strong> dos dados obtidos, ou seja, trabalha diretamente com a criação de estratégias e previsões sobre os dados que estão sendo coletados, afim de criar uma estratégia que vá atingir objetivos futuros. As demais empresas, que não são consideradas <i>data-driven</i>, são aquelas que maniulam seus dados obtidos e geram relatórios com uma <strong>base ultrapassada</strong>, ou seja, viões gerais do que ocorreu no passado de seu ambiente. Imagine uma empresa que obtém inúmeros dados sobre sí mesma e gera um relatório/dashboard/planilha de quantos produtos foram vendidos no mês anterior, etsa é considerada uma empresa comum que se baseis em seus gastos passados. Agora imagine uma empresa que ao coletar dados desse mês anterior, consegue gerar um relatório/dashboard/planilha com uma previsão do que será estimado para daqui 5 qanos, por exemplo, essa sim é uma <i>data-driven interprise</i>.</p>
        <p>Diante disso, dá pra se entender que para os estudos sobre <i>Big Data</i> e essas previsões sobre os dados coletados, são trabalhados pelo termo <strong>Data Science</strong>, a tão comentada ciência dos dados, a qual possui o principal objetivo de gerar análises e estratégias a parti de dados atuais, com uma visão futuristica das possibilidades. Dessa forma, uma empresa poderia se prevenircom acontecimentos futuros e se tornar mais apta a entender suas demandas. Logo, a <i>data science</i> está diretamente ligada as <i>data-driven interprises</i>.</p>
        <p>Outro termo que será deparado com todo este universo dos dados, é sobre o BI, ou <strong>Business Intelligence</strong>, a qual trabalha diretamente com a geração de relatórios e <i>dashboards</i> a partir dos dados que foram coletados. Porém, esses costumam etsra ligados as corporações comuns, que trabalham com análises de dados ultrapassados, gerando uma abordagem para com o que já aconteceu no mbiente.</p>
        <img src="https://danielatllas.github.io/Analytics-BI/BiDataScience.png">
        <p>Porém, enteda que esses não precisam estar em abientes opostos e muito menos devam ser trabalhados de maneira separada, uma vez que ao se juntar os dois ambientes de <i>data science</i> e <i>business intelligence</i>, uma corporativa se torna muito mais forte e capacitada na administração de seus dados, onde o <i>data science</i> poderá auxiliar nas análises de dados ultrapassados, assim como o BI pode auxiliar nos relatórios preditivos dos dados futuros. Diante dessa concatenagem dos dois termos, são exigidas ações, como:</p>
        <ul>
            <li>Coletar dados reais e verdadeiros, os quais devem ser dignos de confiança</li>
            <br>
            <li>Geração de uma boa análise, onde as perspectivas são consideradas na decisão</li>
            <br>
            <li>Condução de decisões concretas, baseadas na coleta de dados verdadeiros e nas análises "perfeitas" desses dados.</li>
        </ul>
        <p>Esses dados, obviamente, precisam estar armazenados em algum lugar, tanto para onde aloca-los quando forem coletados, quanto para consulta-los durante uma análise e criação de relatóios. Para grandes massas de dados, tanto na parte de obtenção e administração dos dados, existem atualmente 3 diferentes aquiteturas que podem amazenar e trabalhar com esses dados de forma direta, entre eles, os <strong>DW (<i>Data Warehouse</i>)</strong>, <strong>PMP (DW massivamente paralelos)</strong> e o <strong>Hadoop</strong>, onde de uma explicativa direta, são:</p>
        <ul>
            <li><strong>Data Warehouse</strong></li>
                <p>Os DW's são grande sistemas de gerenciamento de banco de dados relacionais, otimizados para consultas somente de leitura nesses dados estruturados. Além de fornecerem um alto desempenho e uma fácil adminstração.</p>
                <p>Porém, em sua maioria, são construídos sobre um hardware propietário e são mais caros do que outras aboragens. Assim como, os DW tradicionais possuem esquemas fixos e não são flexivéis para os dados NO-SQL (dados relacionais).</p>
            <li><strong>PMP</strong></li>
                <p>Estes são uma evolução dos DW tradicionais, onde em sua arquitetura, cada servidor têm seu próprio sistema operacional, processador, memória e armazenamento. As atividades desses processadores são coodenados por um processador mestre, que distribui dados entre os nós e coordena ações e resultados.</p>
                <p>Os DW PMP são altamente escaláveis, pois a adição de um processador, resulta no aumento linear do desempenho do ambiente. Além disso, as arquiteturas PMP são também adequadas para trabalhar com vários bancos de dados simultaneamente, tornado-o mais flexível que os DW tradicionais.</p>
                <p>Porém, estes trabalham somente com dados SQL (relacionais), organizados em esquemas, assim como exigem de uma engenharia sofisticada, onde seus propietários, são normalemnte de fornececedores individuais.</p>
            <li><strong>Hadoop</strong></li>
                <p>A arquitetura hadoop se torna semelhante aos DW PMP, com algumas diferenças, onde seus processadores são fracamente acoplados em um cluster hadoop epodem trabalhar e, diferentes fontes de dados. Além disso, o hadoop consegue acomodar tanto dados SQL como dados NO-SQL, tornando-o um ambiente ideal para investigações iterativas.</p>
                <p>Porém, muitas dessas tecnologias relacionadas ao hadoop, ainda estão em um processo de amadurecimento, mesmo que de uma maneira rápida.</p>
        </ul>
        <p>Mas de que forma essas arquiteturas podem estar relacionadas ao <i>Big data</i>? Bom, de uma forma geral, o <i>Big Data</i> e o DW compartilham dos mesmosobjetivos, visando a <strong>entrega de valores de negócio por meio da análise dos dados</strong>. Onde na práica, os <i>Data Warehouses</i> têm a obtenção dos dados a partir de outras bases de dados, como sistemas de marketing de clientes, sistemas de faturamento e etc, ou seja, possuem a principal característica de armazenamento de dados relacionais, sendo o principal banco de dados analítico para esse tipo de armazenamento, como registros fincanceiros e dados de clientes.</p>
        <p>Esse armazenamento massivo de dados transacionais, pode ser ampliado para um sistema de <i>Big Data</i>, o qual se torna com uma maior eficiência para o armazenamento desses e de novas fontes de dados. Este novo sistema ampliado, é chamado de <strong>Data Lake</strong> (ou lago de dados), o qual será explicado posteriormente. Ou seja, essa mudança se dá pelo fato do armazenamento dos dados que não são suportados pelos <i>Data Warehouses</i>, dados como:</p>
        <ul>
            <li>Log's de cliques (Informações de onde e no que foi clicado por um usuário)</li>
            <br>
            <li>Dados de sensores</li>
            <br>
            <li>Dados de localização</li>
            <br>
            <li>Suporte por email</li>
            <br>
            <li>Análise de redes sociais</li>
            <br>
            <li>Comportamento online</li>
            <br>
        </ul>
        <p>No caso do hadoop, sua eficiência se faz por inúmeras necessidades, independente de o ambiente possuir ou não uma massa grande de informações. Entra essas eficiências, as principais são:</p>
        <ul>
            <li>Usar do hadoop como forma de <strong>armazenamento</strong> dos dados para o DW.</li>
            <br>
            <li><strong>Arquitetura</strong> de todos os dados <i>on-premise</i> (armazenados localmente) ou via <i>cloud</i></li>
            <br>
            <li><strong>Acesso a dados</strong> para a extensão do DW, tirando <strong>aproveito de dados normalmente indisponíveis</strong> no ecisistema de <i>Data Warehouse</i>. Além de servir como uma plataforma de depósito para esses dados.</li>
            <br>
        </ul>
        <p>Assim, o hadoop pode ser usado como um <strong>repositório</strong> de armazenamento adicional ou ferramenta para o processamento dos dados, assim como o gerenciamento e análise dessas dados, com o auxílio de putras plataformas e ferramentas.</p>
        <h3>Data Lake</h3>
            <p>Como dito anteriormente, a "transformação" de um <i>Data Warehouse</i> para um <i>Data Lake</i> se faz necessária à medida em que os dados aumentam e também para o uso de dados NO-SQL. Dessa forma, o <i>Data Lake</i> pode trabalhar diretamente com os dados atuais e os novos que serão coletados de outras fontes. </p>
            <p>Para um conhecimento mais fácil do que seria um <i>Data Lake</i>, imagine um <i>datamart</i> como uma loja de água engarrafada, a qual é limpa e embalada, pronta para o consumo. Já o <i>Data Lake</i>, seria como uma grande fonte de água em um estado mais natural/bruto, sendo proveniente de outras fontes que o abastecem e vários suários podem coletar e examinar desse lago. Ou seja, com o <i>data lake</i>, os dados são de certa forma, <strong>registros e informações naturais/brutas</strong> e gerais, e que são coletados de várias fontes de dados distintas.</p>
            <p>O <i>Data Lake</i> enão, <strong>aceita diferentes dados de diferentes locais</strong>, tendo capacidade de manter esses dados originais e suas transformações. Dessa forma, o cientista  de dados usa do <i>Data Lake</i> para analisar esses registros brutos/naturais, transformando-os em <i>insights</i> e relatórios preditivos com o que foi analisado. Por se tratar de uma arquitetura abrangente a qualqu analista, programadores também podem explorar esses registros para análises  em tempo real. Tendo também a capacidade de servir como uma área de preparo para o DW, local onde os dados serão tratados com maior cuidado para gerar <i>dashboards</i> e relatórios.</p>
            <p>Portanto, entenda que o <i>Data Lake</i> surgiu graças as tecnologias de <i>Big Data</i>, com permissão de <strong>armazenamento, processamento e análise</strong> de massas de dados a um custo mais barato que as tecnologias de <i>Data Warehouse</i>. Diante dessa explicação, entenda também, que a arquitetura hadoop <strong>permite a contrução de um data lake</strong>, com capacidade suficiente para o armazenamento de:</p>
            <ul>
                <li><strong>Dados estruturados</strong> - Como tabelas e arquivos CSV</li>
                <br>
                <li><strong>Dados semi-estruturados</strong> - Como logs de sensores e <i>web pages</i></li>
                <br>
                <li><strong>Dados não-estruturados</strong> - Como postagens, fotos, videos e textos</li>
            </ul>
            <p>É importante notar que, embora os DW e o <i>Data Lake</i> sejam repositórios de armazenamento, o <strong>Data Lake não é um subistituto para o Data Warehouse</strong>, pois ambos são otimizados para <strong>diferentes propósitos</strong> e objetivos.</p>
            <p>Em termos gerais, o <i>Data Lake</i> é comercializado como plataforma de gerenciamento de dados, paa analisar fontes distintas de dados em seu formato nativo. Ao invés de colocar dados em um armazenamento específico para um problema, é mais fácil e menos custoso mover esses dados, em seu formato bruto, para um <i>Data Lake</i>. O qual também, resolve o grande problema com <strong>silos/coleções de dados gerenciados de forma independente</strong> em um ambiente corporativo, uma vez que os dados são privados e pouco compartilhados entre os departamentos (onde cada departamento têm seus registros e não costuma divulga-los com os demais). Com o <i>Data Lake</i>, qualquer departamento pode acessar o dado bruto, para nálise ou manipulação (Como as postagens em um SharePoint).</p>
            <p>Porém, há uma questão que deve ser sempre alertada no ambiente corporativo, pois o armazenamento de <strong>dark data</strong> pode levar um <i>Data Lake</i> a se tornar um "pântano".</p>
            <ul>
                <li><strong>Dark Data</strong></li>
                    <p>Os chamados <i>Dark Data</i> são os considerados <strong>dados "inúteis"</strong>, que continuam armazenados no ambiente, onde muitos desses dados <strong>não são acessados</strong>, <strong>não são manipulados</strong> ou até mesmo <strong>não são de conhecimento do propietário</strong>. Dados esses que ocupam um armazenmaneto inútil e até mesmo geram gastos para o seu mantimento.</p>
                    <p>Portanto, é necessária a análise do valor dos dados que estão sendo armazenados, uma vez que seu expurgo pode gerar um grande melhoramento no desempenho para com o ambiente.</p>
                    <img src="https://danielatllas.github.io/Analytics-BI/DarkData1.png">
                    <img src="https://danielatllas.github.io/Analytics-BI/DarkData2.png">
            </ul>
    </body>
</html>